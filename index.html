<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Wells Fargo Analytics : ">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Wells Fargo Analytics</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/jennsoto/wells_fargo_analytics">View on GitHub</a>

          <h1 id="project_title">Wells Fargo Analytics</h1>
          <h2 id="project_tagline"></h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/jennsoto/wells_fargo_analytics/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/jennsoto/wells_fargo_analytics/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1>
<a id="about" class="anchor" href="#about" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>About</strong>
</h1>

<p>Welcome! I'm Jeniffer Soto, student of DATA 101 from the College of Charleston. This space is dedicated to provide information about the Wells Fargo Analytics competition. Feel free to navigate the following sections, which provide related information on the Deliverables. If you have any questions, please contact me at <a href="mailto:sotoperezj@g.cofc.edu">sotoperezj@g.cofc.edu</a></p>

<h1>
<a id="challenge" class="anchor" href="#challenge" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Challenge</strong>
</h1>

<p>Dialogues on social media can provide tremendous insight into the behaviors, desires, pains, and thoughts of consumers. We'd like your help in developing a repeatable process that identifies, classifies, and extracts the underlying drivers of consumer financial conversations and comments in social media data. </p>

<p>Provide an analytic report of 1,500 words or less that is structured as outlined below, utilizing the dataset.txt provided by Wells Fargo.</p>

<h4>
<a id="question-1-what-financial-topics-do-consumers-discuss-on-social-media-and-what-caused-the-consumers-to-post-about-this-topic" class="anchor" href="#question-1-what-financial-topics-do-consumers-discuss-on-social-media-and-what-caused-the-consumers-to-post-about-this-topic" aria-hidden="true"><span class="octicon octicon-link"></span></a>Question 1-<strong>What financial topics do consumers discuss on social media and what caused the consumers to post about this topic?</strong>
</h4>

<h2>
<a id="deliverable-a---describe-your-approach-and-methodology" class="anchor" href="#deliverable-a---describe-your-approach-and-methodology" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Deliverable A - Describe your Approach and Methodology.</strong>
</h2>

<h3>
<a id="preparing-the-data" class="anchor" href="#preparing-the-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preparing the data</h3>

<p>To obtain only the data that's useful out of the 220,377 observations, we upload the data set into the R program and proceed to pre-process the data. When uploaded in R, inspect the type of data dealt with, which in this competition is comments from facebook posts and tweets.  The pre-process consists of getting rid of unnecessary spaces, words, and facebook posts, or tweets. During this phase we select a sample size, in this case of 10,000 observations, to reduce the number of observations we have to work with while staying statistically sound for predictions.  </p>

<p>The team indexed each bank as, BankA, BankB, Bank C, and Bank D. Then we tested the data to find positive and negative sentiment words as well as high frequency words. From these, we can have an idea of the main topics mentioned. The results can be downloaded as an excel file during this step. In this case the excel files created were positive.txt.csv and negative.txt.csv.</p>

<p>After categorizing the csv's files into "relevant" and non-"relevant" to positive or negative comments, we can upload the csv's back to R and train on them for classification purposes. From here, many approaches can be applied, for example clustering approach. </p>

<p><img src="https://raw.githubusercontent.com/jennsoto/wells_fargo_analytics/d37e7cb42a5749583d23ad164b0b4f3a91fe95cd/images/flow%20chart.png" alt="Flow Chart"></p>

<h4>
<a id="code" class="anchor" href="#code" aria-hidden="true"><span class="octicon octicon-link"></span></a>Code</h4>

<div class="highlight highlight-source-r"><pre><span class="pl-c"># Load data set, in my case ('df.Rda')</span>
load(<span class="pl-s"><span class="pl-pds">"</span>/Users/Jenn/Desktop/Analytic_Competition/df.Rda<span class="pl-pds">"</span></span>)
<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-v">FullText</span> <span class="pl-k">=</span> as.character(<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>)

<span class="pl-c"># Grab just the texts, so you can load them in the Corpus</span>
<span class="pl-v">df.texts</span> <span class="pl-k">=</span> as.data.frame(<span class="pl-smi">df</span>[,ncol(<span class="pl-smi">df</span>)])
colnames(<span class="pl-smi">df.texts</span>) <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">'</span>FullText<span class="pl-pds">'</span></span>

<span class="pl-c"># Remove non-ascii characters</span>
<span class="pl-v">df.texts.clean</span> <span class="pl-k">=</span> as.data.frame(iconv(<span class="pl-smi">df.texts</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>, <span class="pl-s"><span class="pl-pds">"</span>latin1<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>ASCII<span class="pl-pds">"</span></span>, <span class="pl-v">sub</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>))
colnames(<span class="pl-smi">df.texts.clean</span>) <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">'</span>FullText<span class="pl-pds">'</span></span>

<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-v">FullText</span> <span class="pl-k">=</span> <span class="pl-smi">df.texts.clean</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>

<span class="pl-c"># If you want to test on just 10000 records using df.10000 created below</span>
<span class="pl-v">idx.10000</span> <span class="pl-k">=</span> sample(<span class="pl-c1">1</span><span class="pl-k">:</span>nrow(<span class="pl-smi">df</span>),<span class="pl-c1">10000</span>)
<span class="pl-v">df.10000</span> <span class="pl-k">=</span> <span class="pl-smi">df</span>[<span class="pl-smi">idx.10000</span>,]

<span class="pl-v">df.entire</span> <span class="pl-k">=</span> <span class="pl-smi">df</span>
<span class="pl-v">df</span> <span class="pl-k">=</span> <span class="pl-smi">df.10000</span>

<span class="pl-c"># Load in corpus form using the tm library</span>
library(<span class="pl-smi">tm</span>) 
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> Corpus(DataframeSource(as.data.frame(<span class="pl-smi">df</span>[,<span class="pl-c1">6</span>])))   

<span class="pl-c"># Perform pre-processing</span>
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">PlainTextDocument</span>)
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">removePunctuation</span>)
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">stripWhitespace</span>)
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">removeWords</span>,c(<span class="pl-s"><span class="pl-pds">"</span>Name<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>and<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>for<span class="pl-pds">"</span></span>)) 
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">removeWords</span>, stopwords(<span class="pl-s"><span class="pl-pds">"</span>english<span class="pl-pds">"</span></span>))
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">removeWords</span>, stopwords(<span class="pl-v">kind</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>SMART<span class="pl-pds">"</span></span>))

save.image(<span class="pl-s"><span class="pl-pds">'</span>docs.preprocessed.Rda<span class="pl-pds">'</span></span>)
load(<span class="pl-s"><span class="pl-pds">'</span>docs.preprocessed.Rda<span class="pl-pds">'</span></span>)</pre></div>

<h3>
<a id="welcome-to-github-page" class="anchor" href="#welcome-to-github-page" aria-hidden="true"><span class="octicon octicon-link"></span></a>Welcome to GitHub Page</h3>

<p>This automatic page generator is the easiest way to create beautiful pages for all of your projects. Author your page content here <a href="https://guides.github.com/features/mastering-markdown/">using GitHub Flavored Markdown</a>, select a template crafted by a designer, and publish. After your page is generated, you can check out the new <code>gh-pages</code> branch locally. If you’re using GitHub Desktop, simply sync your repository and you’ll see the new branch.</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Wells Fargo Analytics maintained by <a href="https://github.com/jennsoto">jennsoto</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
