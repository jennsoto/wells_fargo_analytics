<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Wells Fargo Analytics : ">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Wells Fargo Analytics</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/jennsoto/wells_fargo_analytics">View on GitHub</a>

          <h1 id="project_title">Wells Fargo Analytics</h1>
          <h2 id="project_tagline"></h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/jennsoto/wells_fargo_analytics/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/jennsoto/wells_fargo_analytics/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1>
<a id="about" class="anchor" href="#about" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>About</strong>
</h1>

<p>Welcome! I'm Jeniffer Soto, student of DATA 101 from the College of Charleston. This space is dedicated to provide information about the Wells Fargo Analytics competition. Feel free to navigate the following sections, which provide related information on the Deliverables. If you have any questions, please contact me at <a href="mailto:sotoperezj@g.cofc.edu">sotoperezj@g.cofc.edu</a></p>

<h1>
<a id="challenge" class="anchor" href="#challenge" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Challenge</strong>
</h1>

<p>Dialogues on social media can provide tremendous insight into the behaviors, desires, pains, and thoughts of consumers. We'd like your help in developing a repeatable process that identifies, classifies, and extracts the underlying drivers of consumer financial conversations and comments in social media data. </p>

<p>Provide an analytic report of 1,500 words or less that is structured as outlined below, utilizing the dataset.txt provided by Wells Fargo.</p>

<h4>
<a id="question-1---what-financial-topics-do-consumers-discuss-on-social-media-and-what-caused-the-consumers-to-post-about-this-topic" class="anchor" href="#question-1---what-financial-topics-do-consumers-discuss-on-social-media-and-what-caused-the-consumers-to-post-about-this-topic" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Question 1</strong> - What financial topics do consumers discuss on social media and what caused the consumers to post about this topic?</h4>

<h3>
<a id="deliverable-a---describe-your-approach-and-methodology" class="anchor" href="#deliverable-a---describe-your-approach-and-methodology" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Deliverable A</strong> - Describe your Approach and Methodology.</h3>

<h3>
<a id="preparing-the-data" class="anchor" href="#preparing-the-data" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Preparing the data</strong>
</h3>

<p>To obtain only the data that's useful out of the 220,377 observations, we upload the data set into the R program and proceed to pre-process the data. When uploaded in R, inspect the type of data dealt with, which in this competition is comments from facebook posts and tweets.  The pre-process consists of getting rid of unnecessary spaces, words, and facebook posts, or tweets. During this phase we select a sample size, in this case of 10,000 observations, to reduce the number of observations we have to work with while staying statistically sound for predictions.  </p>

<p>The team indexed each bank as, BankA, BankB, Bank C, and Bank D. Then we tested the data to find positive and negative sentiment words as well as high frequency words. From these, we can have an idea of the main topics mentioned. The results can be downloaded as an excel file during this step. In this case the excel files created were positive.txt.csv and negative.txt.csv.</p>

<p>After categorizing the csv's files into "relevant" and non-"relevant" to positive or negative comments, we can upload the csv's back to R and train on them for classification purposes. From here, many approaches can be applied, for example clustering approach. </p>

<p><img src="https://raw.githubusercontent.com/jennsoto/wells_fargo_analytics/d37e7cb42a5749583d23ad164b0b4f3a91fe95cd/images/flow%20chart.png" alt="Flow Chart"></p>

<h3>
<a id="deliverable-b---discuss-the-data-and-its-relationship-to-social-conversation-drivers" class="anchor" href="#deliverable-b---discuss-the-data-and-its-relationship-to-social-conversation-drivers" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Deliverable B</strong> - Discuss the data and its relationship to social conversation drivers.</h3>

<p>To find the social conversation drivers, indexed the data. After analysing the positive and negative comments we recognized conversation drivers like atm fee, customer service, Wells Fargo donation accounts, and account issues. The data provides an idea of how many banking conversations can be considered as social drivers. </p>

<h3>
<a id="deliverable-c---document-your-code-and-reference-the-analytic-process-flow-diagram-from-deliverable-a" class="anchor" href="#deliverable-c---document-your-code-and-reference-the-analytic-process-flow-diagram-from-deliverable-a" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Deliverable C</strong> - Document your code and reference the analytic process flow-diagram from deliverable A.</h3>

<h4>
<a id="code" class="anchor" href="#code" aria-hidden="true"><span class="octicon octicon-link"></span></a>Code</h4>

<div class="highlight highlight-source-r"><pre><span class="pl-c"># Load data set, in my case ('df.Rda')</span>
load(<span class="pl-s"><span class="pl-pds">"</span>/Users/Jenn/Desktop/Analytic_Competition/df.Rda<span class="pl-pds">"</span></span>)
<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-v">FullText</span> <span class="pl-k">=</span> as.character(<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>)

<span class="pl-c"># Grab just the texts, so you can load them in the Corpus</span>
<span class="pl-v">df.texts</span> <span class="pl-k">=</span> as.data.frame(<span class="pl-smi">df</span>[,ncol(<span class="pl-smi">df</span>)])
colnames(<span class="pl-smi">df.texts</span>) <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">'</span>FullText<span class="pl-pds">'</span></span>

<span class="pl-c"># Remove non-ascii characters</span>
<span class="pl-v">df.texts.clean</span> <span class="pl-k">=</span> as.data.frame(iconv(<span class="pl-smi">df.texts</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>, <span class="pl-s"><span class="pl-pds">"</span>latin1<span class="pl-pds">"</span></span>, 
                                     <span class="pl-s"><span class="pl-pds">"</span>ASCII<span class="pl-pds">"</span></span>, <span class="pl-v">sub</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>))
colnames(<span class="pl-smi">df.texts.clean</span>) <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">'</span>FullText<span class="pl-pds">'</span></span>

<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-v">FullText</span> <span class="pl-k">=</span> <span class="pl-smi">df.texts.clean</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>

<span class="pl-c"># To test on 10000 samples using df.10000</span>
<span class="pl-v">idx.10000</span> <span class="pl-k">=</span> sample(<span class="pl-c1">1</span><span class="pl-k">:</span>nrow(<span class="pl-smi">df</span>),<span class="pl-c1">10000</span>)
<span class="pl-v">df.10000</span> <span class="pl-k">=</span> <span class="pl-smi">df</span>[<span class="pl-smi">idx.10000</span>,]

<span class="pl-v">df.entire</span> <span class="pl-k">=</span> <span class="pl-smi">df</span>
<span class="pl-v">df</span> <span class="pl-k">=</span> <span class="pl-smi">df.10000</span>

<span class="pl-c"># Load in corpus form using the tm library</span>
library(<span class="pl-smi">tm</span>) 
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> Corpus(DataframeSource(as.data.frame(<span class="pl-smi">df</span>[,<span class="pl-c1">6</span>])))   

<span class="pl-c"># Perform pre-processing</span>
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">PlainTextDocument</span>)
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">removePunctuation</span>)
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">stripWhitespace</span>)
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">removeWords</span>,c(<span class="pl-s"><span class="pl-pds">"</span>Name<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>and<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>for<span class="pl-pds">"</span></span>)) 
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">removeWords</span>, stopwords(<span class="pl-s"><span class="pl-pds">"</span>english<span class="pl-pds">"</span></span>))
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">removeWords</span>, stopwords(<span class="pl-v">kind</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>SMART<span class="pl-pds">"</span></span>))

save.image(<span class="pl-s"><span class="pl-pds">'</span>docs.preprocessed.Rda<span class="pl-pds">'</span></span>)
load(<span class="pl-s"><span class="pl-pds">'</span>docs.preprocessed.Rda<span class="pl-pds">'</span></span>)

<span class="pl-c"># Documents containing each bank</span>
<span class="pl-v">bankA.idx</span> <span class="pl-k">=</span> which(sapply(<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>,<span class="pl-k">function</span>(<span class="pl-smi">x</span>) grepl(<span class="pl-s"><span class="pl-pds">"</span>BankA<span class="pl-pds">"</span></span>,<span class="pl-smi">x</span>)))
<span class="pl-v">bankB.idx</span> <span class="pl-k">=</span> which(sapply(<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>,<span class="pl-k">function</span>(<span class="pl-smi">x</span>) grepl(<span class="pl-s"><span class="pl-pds">"</span>BankB<span class="pl-pds">"</span></span>,<span class="pl-smi">x</span>)))
<span class="pl-v">bankC.idx</span> <span class="pl-k">=</span> which(sapply(<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>,<span class="pl-k">function</span>(<span class="pl-smi">x</span>) grepl(<span class="pl-s"><span class="pl-pds">"</span>BankC<span class="pl-pds">"</span></span>,<span class="pl-smi">x</span>)))
<span class="pl-v">bankD.idx</span> <span class="pl-k">=</span> which(sapply(<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>,<span class="pl-k">function</span>(<span class="pl-smi">x</span>) grepl(<span class="pl-s"><span class="pl-pds">"</span>BankD<span class="pl-pds">"</span></span>,<span class="pl-smi">x</span>)))

<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-v">BankID</span> <span class="pl-k">=</span> vector(<span class="pl-v">mode</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>numeric<span class="pl-pds">"</span></span>, <span class="pl-v">length</span> <span class="pl-k">=</span> nrow(<span class="pl-smi">df</span>))
<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">BankID</span>[<span class="pl-smi">bankA.idx</span>] <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>BankA<span class="pl-pds">"</span></span>
<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">BankID</span>[<span class="pl-smi">bankB.idx</span>] <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>BankB<span class="pl-pds">"</span></span>
<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">BankID</span>[<span class="pl-smi">bankC.idx</span>] <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>BankC<span class="pl-pds">"</span></span>
<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">BankID</span>[<span class="pl-smi">bankD.idx</span>] <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>BankD<span class="pl-pds">"</span></span>

<span class="pl-v">bankA.docs</span> <span class="pl-k">=</span> <span class="pl-smi">docs</span>[<span class="pl-smi">bankA.idx</span>]
<span class="pl-v">bankB.docs</span> <span class="pl-k">=</span> <span class="pl-smi">docs</span>[<span class="pl-smi">bankB.idx</span>]
<span class="pl-v">bankC.docs</span> <span class="pl-k">=</span> <span class="pl-smi">docs</span>[<span class="pl-smi">bankC.idx</span>]
<span class="pl-v">bankD.docs</span> <span class="pl-k">=</span> <span class="pl-smi">docs</span>[<span class="pl-smi">bankD.idx</span>]

summary(<span class="pl-smi">docs</span>)

<span class="pl-c">## Repeat these processes for every bank</span>
<span class="pl-c">## Create document term matrix</span>
<span class="pl-smi">dtm</span> <span class="pl-k">&lt;-</span> DocumentTermMatrix(<span class="pl-smi">docs</span>[<span class="pl-smi">bankA.idx</span>])

<span class="pl-c">## Transpose this matrix</span>
<span class="pl-smi">tdm</span> <span class="pl-k">&lt;-</span> TermDocumentMatrix(<span class="pl-smi">docs</span>[<span class="pl-smi">bankA.idx</span>])

<span class="pl-c">## Remove sparse terms</span>
<span class="pl-v">dtm</span> <span class="pl-k">=</span> removeSparseTerms(<span class="pl-smi">dtm</span>, <span class="pl-c1">0.98</span>)

<span class="pl-c">## Organize terms by frequency</span>
findFreqTerms(<span class="pl-smi">dtm</span>,<span class="pl-c1">50</span>)
<span class="pl-smi">freq</span> <span class="pl-k">&lt;-</span> colSums(as.matrix(<span class="pl-smi">dtm</span>))  
<span class="pl-smi">ord</span> <span class="pl-k">&lt;-</span> order(<span class="pl-smi">freq</span>)   
<span class="pl-smi">freq</span>[head(<span class="pl-smi">ord</span>)]  
<span class="pl-smi">freq</span>[tail(<span class="pl-smi">ord</span>)]

<span class="pl-smi">wf</span> <span class="pl-k">&lt;-</span> <span class="pl-k">data.frame</span>(<span class="pl-v">word</span><span class="pl-k">=</span>names(<span class="pl-smi">freq</span>), <span class="pl-v">freq</span><span class="pl-k">=</span><span class="pl-smi">freq</span>)   
head(<span class="pl-smi">wf</span>)

<span class="pl-c">## Plot word frequencies</span>
library(<span class="pl-smi">ggplot2</span>)   
<span class="pl-smi">p</span> <span class="pl-k">&lt;-</span> ggplot(subset(<span class="pl-smi">wf</span>, <span class="pl-smi">freq</span><span class="pl-k">&gt;</span><span class="pl-c1">100</span>), aes(<span class="pl-smi">word</span>, <span class="pl-smi">freq</span>))    
<span class="pl-smi">p</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">p</span> <span class="pl-k">+</span> geom_bar(<span class="pl-v">stat</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>identity<span class="pl-pds">"</span></span>)   
<span class="pl-smi">p</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">p</span> <span class="pl-k">+</span> theme(<span class="pl-v">axis.text.x</span><span class="pl-k">=</span>element_text(<span class="pl-v">angle</span><span class="pl-k">=</span><span class="pl-c1">45</span>, <span class="pl-v">hjust</span><span class="pl-k">=</span><span class="pl-c1">1</span>))   
<span class="pl-smi">p</span>

<span class="pl-c">## To get a word cloud of the 100 most frequent words </span>
library(<span class="pl-smi">wordcloud</span>)
set.seed(<span class="pl-c1">142</span>)   
<span class="pl-smi">dark2</span> <span class="pl-k">&lt;-</span> brewer.pal(<span class="pl-c1">6</span>, <span class="pl-s"><span class="pl-pds">"</span>Dark2<span class="pl-pds">"</span></span>)   
wordcloud(names(<span class="pl-smi">freq</span>), <span class="pl-smi">freq</span>, <span class="pl-v">max.words</span><span class="pl-k">=</span><span class="pl-c1">25</span>, <span class="pl-v">rot.per</span><span class="pl-k">=</span><span class="pl-c1">0.2</span>, <span class="pl-v">colors</span><span class="pl-k">=</span><span class="pl-smi">dark2</span>)

<span class="pl-c"># Sentiment analysis</span>
<span class="pl-smi">pos</span> <span class="pl-k">&lt;-</span> scan(<span class="pl-s"><span class="pl-pds">'</span>positive-words.txt<span class="pl-pds">'</span></span>,<span class="pl-v">what</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>character<span class="pl-pds">'</span></span>,<span class="pl-v">comment.char</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>;<span class="pl-pds">'</span></span>)
<span class="pl-smi">neg</span> <span class="pl-k">&lt;-</span> scan(<span class="pl-s"><span class="pl-pds">'</span>negative-words.txt<span class="pl-pds">'</span></span>,<span class="pl-v">what</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>character<span class="pl-pds">'</span></span>,<span class="pl-v">comment.char</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>;<span class="pl-pds">'</span></span>)

<span class="pl-v">score.sentiment</span> <span class="pl-k">=</span> <span class="pl-k">function</span>(<span class="pl-smi">sentences</span>, <span class="pl-smi">pos.words</span>, <span class="pl-smi">neg.words</span>, <span class="pl-v">.progress</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>none<span class="pl-pds">'</span></span>)
{
  require(<span class="pl-smi">plyr</span>)
  require(<span class="pl-smi">stringr</span>)

  <span class="pl-v">scores</span> <span class="pl-k">=</span> laply(<span class="pl-smi">sentences</span>, <span class="pl-k">function</span>(<span class="pl-smi">sentence</span>, <span class="pl-smi">pos.words</span>, <span class="pl-smi">neg.words</span>) {

    <span class="pl-c"># Clean up sentences with R's regex-driven global substitute, gsub():</span>
    <span class="pl-v">sentence</span> <span class="pl-k">=</span> gsub(<span class="pl-s"><span class="pl-pds">'</span>[[:punct:]]<span class="pl-pds">'</span></span>, <span class="pl-s"><span class="pl-pds">'</span><span class="pl-pds">'</span></span>, <span class="pl-smi">sentence</span>)
    <span class="pl-v">sentence</span> <span class="pl-k">=</span> gsub(<span class="pl-s"><span class="pl-pds">'</span>[[:cntrl:]]<span class="pl-pds">'</span></span>, <span class="pl-s"><span class="pl-pds">'</span><span class="pl-pds">'</span></span>, <span class="pl-smi">sentence</span>)
    <span class="pl-v">sentence</span> <span class="pl-k">=</span> gsub(<span class="pl-s"><span class="pl-pds">'</span><span class="pl-cce">\\</span>d+<span class="pl-pds">'</span></span>, <span class="pl-s"><span class="pl-pds">'</span><span class="pl-pds">'</span></span>, <span class="pl-smi">sentence</span>)
    <span class="pl-v">sentence</span> <span class="pl-k">=</span> tolower(<span class="pl-smi">sentence</span>)

    <span class="pl-c"># Split into words. You need the stringr package</span>
    <span class="pl-v">word.list</span> <span class="pl-k">=</span> str_split(<span class="pl-smi">sentence</span>, <span class="pl-s"><span class="pl-pds">'</span><span class="pl-cce">\\</span>s+<span class="pl-pds">'</span></span>)
    <span class="pl-c"># Sometimes a list() is one level of hierarchy too much</span>
    <span class="pl-v">words</span> <span class="pl-k">=</span> unlist(<span class="pl-smi">word.list</span>)

    <span class="pl-c"># Compare words to positive &amp; negative terms</span>
    <span class="pl-v">pos.matches</span> <span class="pl-k">=</span> match(<span class="pl-smi">words</span>, <span class="pl-smi">pos.words</span>)
    <span class="pl-v">neg.matches</span> <span class="pl-k">=</span> match(<span class="pl-smi">words</span>, <span class="pl-smi">neg.words</span>)

    <span class="pl-c"># match() returns the position of the matched term or NA</span>
    <span class="pl-v">pos.matches</span> <span class="pl-k">=</span> <span class="pl-k">!</span>is.na(<span class="pl-smi">pos.matches</span>)
    <span class="pl-v">neg.matches</span> <span class="pl-k">=</span> <span class="pl-k">!</span>is.na(<span class="pl-smi">neg.matches</span>)

    <span class="pl-c"># TRUE/FALSE will be treated as 1/0 by sum():</span>
    <span class="pl-v">score</span> <span class="pl-k">=</span> sum(<span class="pl-smi">pos.matches</span>) <span class="pl-k">-</span> sum(<span class="pl-smi">neg.matches</span>)

    <span class="pl-k">return</span>(<span class="pl-smi">score</span>)
  }, <span class="pl-smi">pos.words</span>, <span class="pl-smi">neg.words</span>, <span class="pl-v">.progress</span><span class="pl-k">=</span>.<span class="pl-smi">progress</span> )

  <span class="pl-v">scores.df</span> <span class="pl-k">=</span> <span class="pl-k">data.frame</span>(<span class="pl-v">score</span><span class="pl-k">=</span><span class="pl-smi">scores</span>, <span class="pl-v">text</span><span class="pl-k">=</span><span class="pl-smi">sentences</span>)
  <span class="pl-k">return</span>(<span class="pl-smi">scores.df</span>)
}

<span class="pl-c"># Very positive and negative</span>
<span class="pl-v">df.sentiment</span> <span class="pl-k">=</span> <span class="pl-smi">df</span>[<span class="pl-smi">bankA.idx</span>,]

<span class="pl-v">scores</span> <span class="pl-k">=</span> score.sentiment(<span class="pl-smi">df.sentiment</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>, <span class="pl-smi">pos</span>, <span class="pl-smi">neg</span>, <span class="pl-v">.progress</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>text<span class="pl-pds">'</span></span>)
<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-v">very.pos</span> <span class="pl-k">=</span> as.numeric(<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-smi">score</span> <span class="pl-k">&gt;</span><span class="pl-k">=</span> <span class="pl-c1">2</span>)
<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-v">very.neg</span> <span class="pl-k">=</span> as.numeric(<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-smi">score</span> <span class="pl-k">&lt;</span><span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">2</span>)

<span class="pl-v">pos.tweets</span> <span class="pl-k">=</span> which(<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-smi">very.pos</span> <span class="pl-k">==</span> <span class="pl-c1">1</span>)
<span class="pl-v">neg.tweets</span> <span class="pl-k">=</span> which(<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-smi">very.neg</span> <span class="pl-k">==</span> <span class="pl-c1">1</span>)
write.csv(<span class="pl-smi">df.sentiment</span>[<span class="pl-smi">pos.tweets</span>,],<span class="pl-v">file</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>pos.texts.csv<span class="pl-pds">'</span></span>)<span class="pl-c">##creates positive</span>
write.csv(<span class="pl-smi">df.sentiment</span>[<span class="pl-smi">neg.tweets</span>,],<span class="pl-v">file</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>neg.texts.csv<span class="pl-pds">'</span></span>)<span class="pl-c">##creates negative</span>

<span class="pl-c"># Creating a Classifier</span>
load(<span class="pl-s"><span class="pl-pds">'</span>df.Rda<span class="pl-pds">'</span></span>)
<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-v">FullText</span> <span class="pl-k">=</span> as.character(<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>)
<span class="pl-v">pos.texts</span> <span class="pl-k">=</span> read.csv(<span class="pl-s"><span class="pl-pds">'</span>pos.texts.csv<span class="pl-pds">'</span></span>,<span class="pl-v">header</span><span class="pl-k">=</span><span class="pl-c1">T</span>)
<span class="pl-smi">pos.texts</span><span class="pl-k">$</span><span class="pl-v">FullText</span> <span class="pl-k">=</span> as.character(<span class="pl-smi">pos.texts</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>)
colnames(<span class="pl-smi">pos.texts</span>)
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> Corpus(DataframeSource(as.data.frame(<span class="pl-smi">pos.texts</span>[,<span class="pl-c1">9</span>])))   
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">PlainTextDocument</span>)

<span class="pl-smi">dtm</span> <span class="pl-k">&lt;-</span> DocumentTermMatrix(<span class="pl-smi">docs</span>)

<span class="pl-smi">tdm</span> <span class="pl-k">&lt;-</span> TermDocumentMatrix(<span class="pl-smi">docs</span>)

<span class="pl-v">m</span> <span class="pl-k">=</span> as.matrix(<span class="pl-smi">dtm</span>)

<span class="pl-v">df.classification</span> <span class="pl-k">=</span> as.data.frame(<span class="pl-smi">m</span>) <span class="pl-c">#dataframe</span>
<span class="pl-smi">df.classification</span><span class="pl-k">$</span><span class="pl-v">Relevant</span> <span class="pl-k">=</span> <span class="pl-smi">pos.texts</span><span class="pl-k">$</span><span class="pl-smi">Relevant</span>
<span class="pl-smi">df.classification</span><span class="pl-k">$</span><span class="pl-smi">Relevant</span>

<span class="pl-c"># Grow a tree</span>
library(<span class="pl-smi">rpart</span>)
<span class="pl-smi">fit</span><span class="pl-k">&lt;-</span>rpart(<span class="pl-smi">Relevant</span> <span class="pl-k">~</span> <span class="pl-smi">X</span> <span class="pl-k">+</span> <span class="pl-smi">AutoID</span> <span class="pl-k">+</span> <span class="pl-smi">Date</span> <span class="pl-k">+</span> <span class="pl-smi">Year</span> <span class="pl-k">+</span> <span class="pl-smi">Month</span> <span class="pl-k">+</span> <span class="pl-smi">MediaType</span> <span class="pl-k">+</span> <span class="pl-smi">FullText</span>  
           <span class="pl-k">+</span> <span class="pl-smi">BankID</span>, <span class="pl-v">data</span> <span class="pl-k">=</span> <span class="pl-smi">pos.texts</span>, <span class="pl-v">method</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>class<span class="pl-pds">"</span></span>)
printcp(<span class="pl-smi">fit</span>) <span class="pl-c"># display the results </span>
plotcp(<span class="pl-smi">fit</span>) <span class="pl-c"># visualize cross-validation results </span>
summary(<span class="pl-smi">fit</span>) <span class="pl-c"># detailed summary of splits</span>

<span class="pl-c">########### Clustering approach</span>
<span class="pl-v">dtm</span> <span class="pl-k">=</span> DocumentTermMatrix(<span class="pl-smi">docs</span>)
<span class="pl-v">dtm</span> <span class="pl-k">=</span> removeSparseTerms(<span class="pl-smi">dtm</span>, <span class="pl-c1">0.98</span>)
<span class="pl-v">bag.of.words</span> <span class="pl-k">=</span> as.matrix(<span class="pl-smi">dtm</span>)
<span class="pl-smi">dtm</span>

<span class="pl-v">hc</span> <span class="pl-k">=</span> hclust(dist(<span class="pl-smi">bag.of.words</span>))
<span class="pl-v">hcd</span> <span class="pl-k">=</span> as.dendrogram(<span class="pl-smi">hc</span>)
<span class="pl-v">g246</span> <span class="pl-k">=</span> cutree(<span class="pl-smi">hc</span>, <span class="pl-v">k</span><span class="pl-k">=</span>c(<span class="pl-c1">2</span>,<span class="pl-c1">4</span>,<span class="pl-c1">6</span>,<span class="pl-c1">20</span>))
<span class="pl-v">group.idxs</span> <span class="pl-k">=</span> <span class="pl-k">list</span>()
<span class="pl-v">n.groups</span> <span class="pl-k">=</span> <span class="pl-c1">20</span>
<span class="pl-v">dtms</span> <span class="pl-k">=</span> <span class="pl-k">list</span>()
<span class="pl-v">dtms.matrcies</span> <span class="pl-k">=</span> <span class="pl-k">list</span>()
<span class="pl-k">for</span> (<span class="pl-smi">i</span> <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-smi">n.groups</span>) {
  <span class="pl-smi">group.idxs</span>[[<span class="pl-smi">i</span>]] <span class="pl-k">=</span> which(<span class="pl-smi">g246</span>[,<span class="pl-s"><span class="pl-pds">"</span>20<span class="pl-pds">"</span></span>]<span class="pl-k">==</span><span class="pl-smi">i</span>)
  <span class="pl-smi">dtms</span>[[<span class="pl-smi">i</span>]] <span class="pl-k">=</span> DocumentTermMatrix(<span class="pl-smi">docs</span>[<span class="pl-smi">group.idxs</span>[[<span class="pl-smi">i</span>]]])
  <span class="pl-v">dtm.matrix</span> <span class="pl-k">=</span> as.matrix(<span class="pl-smi">dtms</span>[[<span class="pl-smi">i</span>]])
  print(paste0(<span class="pl-s"><span class="pl-pds">'</span>Group,i<span class="pl-pds">'</span></span>))
  <span class="pl-v">frequency</span> <span class="pl-k">=</span> colSums(<span class="pl-smi">dtm.matrix</span>)
  <span class="pl-v">frequency</span> <span class="pl-k">=</span> sort(<span class="pl-smi">frequency</span>, <span class="pl-v">decreasing</span> <span class="pl-k">=</span> <span class="pl-c1">TRUE</span>)
  print(head(<span class="pl-smi">frequency</span>))
}</pre></div>

<h4>
<a id="question-2---are-the-topics-and-substance-consistent-across-the-industry-or-are-they-isolated-to-individual-banks" class="anchor" href="#question-2---are-the-topics-and-substance-consistent-across-the-industry-or-are-they-isolated-to-individual-banks" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Question #2</strong> - Are the topics and “substance” consistent across the industry or are they isolated to individual banks?</h4>

<h3>
<a id="deliverable-d----create-a-list-of-topics-and-substance-you-found" class="anchor" href="#deliverable-d----create-a-list-of-topics-and-substance-you-found" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Deliverable D</strong> -  Create a list of topics and substance you found.</h3>

<h4>
<a id="topics" class="anchor" href="#topics" aria-hidden="true"><span class="octicon octicon-link"></span></a>Topics:</h4>

<ul>
<li>Account</li>
<li>Check</li>
<li>Customer Service </li>
<li>Credit</li>
<li>Grants </li>
<li>Management</li>
<li>ATM</li>
<li>Phone Calls</li>
</ul>

<h4>
<a id="substance" class="anchor" href="#substance" aria-hidden="true"><span class="octicon octicon-link"></span></a>Substance:</h4>

<ul>
<li>Customer Attrition — Likes customer service/dislikes customer service</li>
</ul>

<h3>
<a id="deliverable-e---create-a-narrative-of-insights-supported-by-the-quantitative-results-should-include-graphs-or-charts" class="anchor" href="#deliverable-e---create-a-narrative-of-insights-supported-by-the-quantitative-results-should-include-graphs-or-charts" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Deliverable E</strong> - Create a narrative of insights supported by the quantitative results (should include graphs or charts).</h3>

<p>The most frequent words obtained served as a guide to understand what subjects customers are talking about. According to our results, customers are commenting about online services, phone calls, customer service, and bank accounts. </p>

<p>According to the classification tree results, positive statements within a .5 relevancy are "thanks," "very," "service," "support," "love," and "thank." With more work on the csv's files, we could utilize this method to obtain only the positive or negative comments.</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Wells Fargo Analytics maintained by <a href="https://github.com/jennsoto">jennsoto</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
